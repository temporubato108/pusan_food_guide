import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import matplotlib.font_manager as fm
import warnings
from wordcloud import WordCloud
from collections import Counter
from konlpy.tag import Okt
import folium
from folium.plugins import MarkerCluster
from streamlit_folium import folium_static
import json
import openai

# st.secretsë¡œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = st.secrets["OPENAI_API_KEY"]

# API í‚¤ë¥¼ ì´ìš©í•´ OpenAI API í˜¸ì¶œí•˜ê¸°
openai.api_key = api_key

def get_chatbot_response(user_input, restaurant_data):
    if not api_key:
        return "API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
        
    try:
        # OpenAI API í‚¤ ì„¤ì •
        openai.api_key = api_key
        
        # ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if restaurant_data.empty:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„ íƒí•˜ì‹  ì§€ì—­ê³¼ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ìŒì‹ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # í˜„ì¬ êµ¬ ì •ë³´ ì¶”ì¶œ
        current_district = None
        for district in districts.keys():
            if district in restaurant_data['ì£¼ì†Œ'].iloc[0]:
                current_district = district
                break
        if not current_district:
            current_district = "ë¶€ì‚°"  # ê¸°ë³¸ê°’ ì„¤ì •
                
        # í˜„ì¬ ì¹´í…Œê³ ë¦¬ ì •ë³´
        current_category = reverse_category_mapping.get(
            restaurant_data['ìŒì‹ì  ì¹´í…Œê³ ë¦¬'].iloc[0], 
            "ê¸°íƒ€"
        )
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        system_prompt = f"""ë‹¹ì‹ ì€ ë¶€ì‚°ì˜ ë§›ì§‘ì„ ì¶”ì²œí•´ì£¼ëŠ” ì „ë¬¸ ì±—ë´‡ì…ë‹ˆë‹¤. 
í˜„ì¬ {current_district}ì˜ {current_category} ìŒì‹ì  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
ì¶”ì²œì‹œ ìŒì‹ì  ì´ë¦„, ì£¼ì†Œ, ëŒ€í‘œë©”ë‰´, ë³„ì  ë“±ì˜ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
ì‘ë‹µì€ ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”."""
        
        # ë ˆìŠ¤í† ë‘ ì •ë³´ ì¤€ë¹„
        restaurant_info = restaurant_data[['ìŒì‹ì  ì´ë¦„', 'ì£¼ì†Œ', 'ë³„ì ', 'ìŒì‹ì  ì¹´í…Œê³ ë¦¬']].copy()
        
        # ëŒ€í‘œë©”ë‰´ ì •ë³´ ì¶”ê°€
        if 'ë©”ë‰´ ì´ë¦„' in restaurant_data.columns and 'ë©”ë‰´ ê°€ê²©' in restaurant_data.columns:
            restaurant_info['ëŒ€í‘œë©”ë‰´'] = restaurant_data.apply(
                lambda x: f"{eval(x['ë©”ë‰´ ì´ë¦„'])[0]} ({eval(x['ë©”ë‰´ ê°€ê²©'])[0]}ì›)" 
                if isinstance(x['ë©”ë‰´ ì´ë¦„'], str) and len(eval(x['ë©”ë‰´ ì´ë¦„'])) > 0 
                else "ë©”ë‰´ ì •ë³´ ì—†ìŒ",
                axis=1
            )
        else:
            restaurant_info['ëŒ€í‘œë©”ë‰´'] = "ë©”ë‰´ ì •ë³´ ì—†ìŒ"
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        restaurant_info = restaurant_info.fillna({
            'ìŒì‹ì  ì´ë¦„': 'ì •ë³´ ì—†ìŒ',
            'ì£¼ì†Œ': 'ì •ë³´ ì—†ìŒ',
            'ë³„ì ': 'ì •ë³´ ì—†ìŒ',
            'ëŒ€í‘œë©”ë‰´': 'ì •ë³´ ì—†ìŒ',
            'ìŒì‹ì  ì¹´í…Œê³ ë¦¬': 'ì •ë³´ ì—†ìŒ'
        })
        
        # ë°ì´í„° í¬ê¸° ì œí•œ
        info_records = restaurant_info.head(10).to_dict('records')
        
        context = f"í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë ˆìŠ¤í† ë‘ ì •ë³´:\n{str(info_records)}"
        
        # OpenAI API í˜¸ì¶œ
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"{context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_input}"}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(f"Error details: {e.__class__.__name__} - {str(e)}")
        return error_message

# í•œê¸€ í°íŠ¸ ì„¤ì •
font_path = "c:/Windows/Fonts/malgun.ttf"
font_name = fm.FontProperties(fname=font_path).get_name()
plt.rc('font', family=font_name)

# ê²½ê³  ë¬´ì‹œ ì„¤ì •
warnings.filterwarnings("ignore", category=UserWarning)

# ì‚¬ìš©ì ì •ì˜ í•œêµ­ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
korean_stopwords = set([
    "ìˆìŠµë‹ˆë‹¤", "ìˆë‹¤", "í•˜ëŠ”", "í• ", "í•©ë‹ˆë‹¤", "í•œ", "ìˆê³ ", "ê²ƒ", "ë“±", 
    "í•˜ê³ ", "ì—ì„œ", "ì´ë‹¤", "ê·¸ë¦¬ê³ ", "ê·¸", "ì €", "ì´", "ë¥¼", "ì—", "ì˜", "ê°€", "ë“¤"
    # í•„ìš”í•œ ê²½ìš° ë¶ˆìš©ì–´ë¥¼ ë” ì¶”ê°€í•˜ì„¸ìš”.
])

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì •ì˜
category_mapping = {
    'í•œì‹': ['í•œì‹', 'ìœ¡ë¥˜,ê³ ê¸°ìš”ë¦¬', 'ì†Œê³ ê¸°êµ¬ì´', 'ë¼ì§€ê³ ê¸°êµ¬ì´', 'ê³±ì°½,ë§‰ì°½,ì–‘', 'êµ­ë°¥'],
    'ì¼ì‹': ['ì¼ì‹ë‹¹', 'ì´ìì¹´ì•¼', 'ìƒì„ íšŒ'],
    'ì¤‘ì‹': ['ì¤‘ì‹ë‹¹'],
    'ì–‘ì‹': ['ì–‘ì‹', 'ìŠ¤íŒŒê²Œí‹°,íŒŒìŠ¤íƒ€ì „ë¬¸', 'ë¸ŒëŸ°ì¹˜', 'ëˆê°€ìŠ¤'],
    'ì¹´í˜': ['ì¹´í˜', 'ì¹´í˜,ë””ì €íŠ¸', 'ë¸ŒëŸ°ì¹˜ì¹´í˜', 'ë–¡ì¹´í˜'],
    'ë² ì´ì»¤ë¦¬': ['ë² ì´ì»¤ë¦¬'],
    'ê¸°íƒ€': ['ì•„ì‹œì•„ìŒì‹', 'íƒœêµ­ìŒì‹']  
}

# ê°„ë‹¨í•œ ê°ì • ì‚¬ì „
sentiment_dict = {
    'ì¢‹': 1, 'í›Œë¥­': 1, 'ë§›ìˆ': 1, 'ìµœê³ ': 1, 'ì¹œì ˆ': 1,
    'ë‚˜ì˜': -1, 'ë³„ë¡œ': -1, 'ìµœì•…': -1, 'ë¶ˆì¹œì ˆ': -1, 'ì‹¤ë§': -1
}

def analyze_sentiment(text):
    okt = Okt()
    tokens = okt.morphs(text)
    sentiment_score = sum(sentiment_dict.get(token, 0) for token in tokens)
    return sentiment_score

# ì—­ë°©í–¥ ë§¤í•‘ ìƒì„±
reverse_category_mapping = {}
for main_category, sub_categories in category_mapping.items():
    for sub_category in sub_categories:
        reverse_category_mapping[sub_category] = main_category

# ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± í•¨ìˆ˜
def create_sentiment_wordcloud(reviews):
    okt = Okt()
    sentiment_words = []
    
    for review in reviews:
        # í˜•íƒœì†Œ ë¶„ì„
        tokens = okt.pos(review)
        
        # ê°ì • ë¶„ì„
        sentiment = analyze_sentiment(review)
        
        # í˜•ìš©ì‚¬ì™€ ë¶€ì‚¬ë§Œ ì„ íƒ
        for word, pos in tokens:
            if pos in ['Adjective', 'Adverb'] and word not in korean_stopwords:
                if sentiment > 0:
                    sentiment_words.append(word + '_positive')
                elif sentiment < 0:
                    sentiment_words.append(word + '_negative')
                else:
                    sentiment_words.append(word + '_neutral')

    # ë‹¨ì–´ ë¹ˆë„ìˆ˜ ê³„ì‚°
    word_counts = Counter(sentiment_words)

    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    wordcloud = WordCloud(
        font_path="c:/Windows/Fonts/malgun.ttf",
        width=800,
        height=800,
        background_color="white",
        colormap='RdYlGn'  # Red for negative, Yellow for neutral, Green for positive
    ).generate_from_frequencies(word_counts)
    
    return wordcloud

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="ë¶€ì‚°ì‹œ ë§›ì§‘ ì¶”ì²œ ì‹œìŠ¤í…œ")

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown(
    """
    <style>
    .main {
        padding: 0rem 1rem;
    }
    .stButton>button {
        width: 100%;
        background-color: #009688;
        color: white;
        border: none;
        padding: 0.5rem;
        border-radius: 5px;
    }
    .stButton>button:hover {
        background-color: #00796b;
    }
    .sidebar-content {
        padding: 1rem;
        background-color: #f5f5f5;
        border-radius: 5px;
        margin-bottom: 1rem;
    }
    .restaurant-card {
        background-color: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# CSV íŒŒì¼ë“¤ì´ ì €ì¥ëœ ê²½ë¡œ
csv_folder_path = r'C:\Users\wonho\Downloads\workspace\project\ë¶€ì‚°ì‹œ_ë§›ì§‘_ì¶”ì²œ_ì‹œìŠ¤í…œ\ë¶€ì‚°_ìŒì‹ì _ë°ì´í„°_with_lat_lon'

# êµ¬ë³„ë¡œ CSV íŒŒì¼ ëª©ë¡
districts = {
    "ê°•ì„œêµ¬": "ë¶€ì‚°_ìŒì‹ì _ê°•ì„œêµ¬_with_lat_lon.csv",
    "ê¸ˆì •êµ¬": "ë¶€ì‚°_ìŒì‹ì _ê¸ˆì •êµ¬_with_lat_lon.csv",
    "ê¸°ì¥êµ°": "ë¶€ì‚°_ìŒì‹ì _ê¸°ì¥êµ°_with_lat_lon.csv",
    "ë‚¨êµ¬": "ë¶€ì‚°_ìŒì‹ì _ë‚¨êµ¬_with_lat_lon.csv",
    "ë™êµ¬": "ë¶€ì‚°_ìŒì‹ì _ë™êµ¬_with_lat_lon.csv",
    "ë™ë˜êµ¬": "ë¶€ì‚°_ìŒì‹ì _ë™ë˜êµ¬_with_lat_lon.csv",
    "ë¶€ì‚°ì§„êµ¬": "ë¶€ì‚°_ìŒì‹ì _ë¶€ì‚°ì§„êµ¬_with_lat_lon.csv",
    "ë¶êµ¬": "ë¶€ì‚°_ìŒì‹ì _ë¶êµ¬_with_lat_lon.csv",
    "ì‚¬ìƒêµ¬": "ë¶€ì‚°_ìŒì‹ì _ì‚¬ìƒêµ¬_with_lat_lon.csv",
    "ì„œêµ¬": "ë¶€ì‚°_ìŒì‹ì _ì„œêµ¬_with_lat_lon.csv",
    "ìˆ˜ì˜êµ¬": "ë¶€ì‚°_ìŒì‹ì _ìˆ˜ì˜êµ¬_with_lat_lon.csv",
    "ì—°ì œêµ¬": "ë¶€ì‚°_ìŒì‹ì _ì—°ì œêµ¬_with_lat_lon.csv",
    "ì˜ë„êµ¬": "ë¶€ì‚°_ìŒì‹ì _ì˜ë„êµ¬_with_lat_lon.csv",
    "ì¤‘êµ¬": "ë¶€ì‚°_ìŒì‹ì _ì¤‘êµ¬_with_lat_lon.csv",
    "í•´ìš´ëŒ€êµ¬": "ë¶€ì‚°_ìŒì‹ì _í•´ìš´ëŒ€êµ¬_with_lat_lon.csv"
}

# ì„ íƒí•œ êµ¬ì— í•´ë‹¹í•˜ëŠ” CSV íŒŒì¼ ë¡œë“œ ë° í•„í„°ë§ì„ ì‚¬ì´ë“œë°” ì‹œì‘ ì „ì— ìˆ˜í–‰
selected_district = list(districts.keys())[0]  # ê¸°ë³¸ê°’ ì„¤ì •
selected_category = 'í•œì‹'  # ê¸°ë³¸ê°’ ì„¤ì •

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("ë¶€ì‚°ì‹œ êµ¬ ì„ íƒ")
    st.markdown("---")

    # êµ¬ ì„ íƒ
    selected_district = st.selectbox('êµ¬ ì„ íƒ', list(districts.keys()))

    # ìŒì‹ì  ì¹´í…Œê³ ë¦¬ ì„ íƒ
    main_categories = ['í•œì‹', 'ì¼ì‹', 'ì¤‘ì‹', 'ì–‘ì‹', 'ì¹´í˜', 'ë² ì´ì»¤ë¦¬']
    selected_category = st.selectbox('ìŒì‹ì  ì¹´í…Œê³ ë¦¬ ì„ íƒ', main_categories)

    # CSV íŒŒì¼ ë¡œë“œ ë° í•„í„°ë§
    csv_file = os.path.join(csv_folder_path, districts[selected_district])
    df = pd.read_csv(csv_file)
    
    # ì„ íƒí•œ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§
    df['ëŒ€ë¶„ë¥˜'] = df['ìŒì‹ì  ì¹´í…Œê³ ë¦¬'].map(reverse_category_mapping)
    filtered_df = df[df['ëŒ€ë¶„ë¥˜'] == selected_category]

    # ì„ íƒëœ ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ì— í¬í•¨ëœ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ í‘œì‹œ
    sub_categories = [sub_category for sub_category in category_mapping[selected_category]]
    st.markdown("### í¬í•¨ëœ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬")
    st.write(", ".join(sub_categories))

    st.markdown("---")
    st.markdown("## ë§›ì§‘ ì¶”ì²œ ì±—ë´‡ ğŸ¤–")
    st.markdown("""
    ì•ˆë…•í•˜ì„¸ìš”! ë¶€ì‚° ë§›ì§‘ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤.
    ì›í•˜ì‹œëŠ” ë§›ì§‘ì„ ì°¾ì•„ë“œë¦´ê²Œìš”!
    
    ğŸ’¡ ì´ëŸ° ê²ƒë“¤ì„ ë¬¼ì–´ë³´ì„¸ìš”:
    - "í•´ìš´ëŒ€ ê·¼ì²˜ íšŒ ë§›ì§‘ ì¶”ì²œí•´ì£¼ì„¸ìš”"
    - "ê°€ì¡±ê³¼ í•¨ê»˜ ê°€ê¸° ì¢‹ì€ í•œì‹ë‹¹ì€?"
    - "ë°ì´íŠ¸í•˜ê¸° ì¢‹ì€ ë¶„ìœ„ê¸°ì˜ ë ˆìŠ¤í† ë‘ ì¶”ì²œí•´ì£¼ì„¸ìš”"
    """)

    # st.session_state.messages ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    # API í‚¤ ìƒíƒœ í™•ì¸
    if not api_key:
        st.error("API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.")
    else:
        # ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
        user_input = st.text_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", key="chatbot_input")
        
        if user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            st.session_state.messages.append({"role": "user", "content": user_input})
            
            # ì±—ë´‡ ì‘ë‹µ ìƒì„±
            with st.spinner('ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                response = get_chatbot_response(user_input, filtered_df)
            
            # ì±—ë´‡ ì‘ë‹µ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": response})
        
        # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
        st.markdown("### ëŒ€í™” ë‚´ì—­")
        for message in st.session_state.messages[-6:]:  # ìµœê·¼ 3ê°œì˜ ëŒ€í™”ìŒë§Œ í‘œì‹œ
            if message["role"] == "user":
                st.markdown(f"ğŸ‘¤ **You**: {message['content']}")
            else:
                st.markdown(f"ğŸ¤– **Bot**: {message['content']}")
        
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ëŒ€í™” ì´ˆê¸°í™”", key="clear_chat"):
            st.session_state.messages = []
            st.experimental_rerun()

# ì„ íƒí•œ êµ¬ì— í•´ë‹¹í•˜ëŠ” CSV íŒŒì¼ ë¡œë“œ
csv_file = os.path.join(csv_folder_path, districts[selected_district])
df = pd.read_csv(csv_file)

# ì„ íƒí•œ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§
df['ëŒ€ë¶„ë¥˜'] = df['ìŒì‹ì  ì¹´í…Œê³ ë¦¬'].map(reverse_category_mapping)
filtered_df = df[df['ëŒ€ë¶„ë¥˜'] == selected_category]

# folium ì§€ë„ ìƒì„± í•¨ìˆ˜
def create_map(df):
    m = folium.Map(location=[35.1796, 129.0756], zoom_start=11)
    marker_cluster = MarkerCluster().add_to(m)

    for idx, row in df.iterrows():
        folium.Marker(
            location=[row['ìœ„ë„'], row['ê²½ë„']],
            popup=folium.Popup(f"<b>{row['ìŒì‹ì  ì´ë¦„']}</b><br>{row['ì£¼ì†Œ']}<br>{row['ìŒì‹ì  ì¹´í…Œê³ ë¦¬']}", max_width=300),
            tooltip=row['ìŒì‹ì  ì´ë¦„']
        ).add_to(marker_cluster)

    return m

# ë©”ì¸ ì»¨í…ì¸ ë¥¼ 3ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„í• 
col1, col2, col3 = st.columns([2, 1, 2])

with col1:
    st.markdown(f"## {selected_district} ë§›ì§‘ ëª©ë¡")
    
    # ì¶”ì²œ ì‹ë‹¹ ëª©ë¡ ì¶œë ¥
    for idx, row in filtered_df.iterrows():
        # ë³„ì ì´ NaNì¸ ê²½ìš° ì²˜ë¦¬
        if pd.isna(row['ë³„ì ']):
            star_rating = 'â­ ë³„ì  ë¯¸ê³µê°œ'
        else:
            star_rating = f"â­ ë³„ì : {row['ë³„ì ']}"

        st.markdown(f"""
        <div class="restaurant-card">
            <h3>{row['ìŒì‹ì  ì´ë¦„']}</h3>
            <div class="subcategory-info">
                ì¹´í…Œê³ ë¦¬: {row['ìŒì‹ì  ì¹´í…Œê³ ë¦¬']}
            </div>
            <div class="metric-container" style="background-color: #e0f7fa; padding: 10px; border-radius: 8px;">
                <span style="font-size: 20px;">{star_rating}</span> | 
                <span>ğŸ‘¥ ë°©ë¬¸ì ë¦¬ë·°: {row['ë°©ë¬¸ì ë¦¬ë·° ìˆ˜']}</span> | 
                <span>ğŸ“ ë¸”ë¡œê·¸ ë¦¬ë·°: {row['ë¸”ë¡œê·¸ ë¦¬ë·° ìˆ˜']}</span>
            </div>
                <p>ğŸ“ ì£¼ì†Œ: {row['ì£¼ì†Œ']}</p>
                <p>ğŸ“ ì „í™”ë²ˆí˜¸: {row['ì „í™”ë²ˆí˜¸']}</p>
            </div>
            """, unsafe_allow_html=True)

        # ìƒì„¸ ì •ë³´ ë³´ê¸° ë²„íŠ¼
        if st.button(f"ìƒì„¸ ì •ë³´ - {row['ìŒì‹ì  ì´ë¦„']}", key=f"toggle-{idx}"):
            st.session_state[f"details-{idx}"] = not st.session_state.get(f"details-{idx}", False)
        
        # ìƒì„¸ ì •ë³´ ì—´ê³  ë‹«ê¸° ê¸°ëŠ¥
        if st.session_state.get(f"details-{idx}", False):
            # ë©”ë‰´ ì •ë³´ ì¶œë ¥
            with st.expander("ë©”ë‰´ ë”ë³´ê¸°"):
                st.markdown("### ë©”ë‰´ ëª©ë¡")
                menu_photos = eval(row['ë©”ë‰´ ì‚¬ì§„'])
                menu_names = eval(row['ë©”ë‰´ ì´ë¦„'])
                menu_prices = eval(row['ë©”ë‰´ ê°€ê²©'])

                cols = st.columns(3)
                for i, (photo_url, name, price) in enumerate(zip(menu_photos, menu_names, menu_prices)):
                    with cols[i % 3]:
                        st.image(photo_url, caption=f"{name} - {price}ì›", use_column_width=True)

            # ë¦¬ë·° ì¶œë ¥ ë° ì›Œë“œ í´ë¼ìš°ë“œ
            with st.expander("ë¦¬ë·° ë”ë³´ê¸°"):
                if isinstance(row['ë¦¬ë·°'], str):
                    try:
                        # JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì‹œë„
                        reviews = json.loads(row['ë¦¬ë·°'])
                    except json.JSONDecodeError:
                        # JSON í˜•ì‹ì´ ì•„ë‹ ê²½ìš° eval ì‚¬ìš©
                        try:
                            reviews = eval(row['ë¦¬ë·°'])
                        except Exception as e:
                            st.error(f"ë¦¬ë·° ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                            reviews = []  # ì—ëŸ¬ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
                else:
                    st.warning("ë¦¬ë·° ë°ì´í„°ê°€ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤.")
                    reviews = []

                st.write(reviews)

                # ë¦¬ë·° ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šì„ ë•Œë§Œ ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„±
                if reviews:
                    try:
                        sentiment_wordcloud = create_sentiment_wordcloud(reviews)
                        st.image(sentiment_wordcloud.to_array(), caption="ë¦¬ë·°ì˜ ê°ì •ì„ ë¶„ì„í•œ ì›Œë“œ í´ë¼ìš°ë“œ")
                    except ValueError as e:
                        st.error(f"ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                else:
                    st.warning("ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

with col2:
    st.markdown("## ë¦¬ë·° ë¶„í¬ ë¶„ì„")
    
    # ë¦¬ë·° ë¶„í¬ ê·¸ë˜í”„
    if not filtered_df.empty:
        plt.figure(figsize=(12, 8))
        total_reviews = filtered_df['ë°©ë¬¸ì ë¦¬ë·° ìˆ˜'] + filtered_df['ë¸”ë¡œê·¸ ë¦¬ë·° ìˆ˜']
        plt.hist(total_reviews, bins=20, color='#009688', alpha=0.7)
        plt.title(f'{selected_district} ìŒì‹ì  ë¦¬ë·° ë¶„í¬', fontsize=14)
        plt.xlabel('ì´ ë¦¬ë·° ìˆ˜', fontsize=12)
        plt.ylabel('ìŒì‹ì  ìˆ˜', fontsize=12)
        st.pyplot(plt)
        
        # ë¦¬ë·° í†µê³„
        st.markdown("## ë¦¬ë·° í†µê³„")
        with st.container():
            st.markdown(f"""
            <div class="metric-container">
                í‰ê·  ë¦¬ë·° ìˆ˜: {total_reviews.mean():.1f}<br>
                ìµœëŒ€ ë¦¬ë·° ìˆ˜: {total_reviews.max()}<br>
                ìµœì†Œ ë¦¬ë·° ìˆ˜: {total_reviews.min()}<br>
                ì´ ìŒì‹ì  ìˆ˜: {len(filtered_df)}
            </div>
            """, unsafe_allow_html=True)
    else:
        st.warning(f"{selected_district}ì— í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ìŒì‹ì ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("## ë§›ì§‘ ì§€ë„")
    
    if not filtered_df.empty:
        # ì§€ë„ ìƒì„±
        map = create_map(filtered_df)
        
        # Streamlitì— ì§€ë„ í‘œì‹œ
        folium_static(map)
    else:
        st.warning(f"{selected_district}ì— í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ìŒì‹ì ì´ ì—†ìŠµë‹ˆë‹¤.")
